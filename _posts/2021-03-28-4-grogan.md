---
layout: post
title: "Dictionary Approaches to QAnon Discussion (Grogan)"
author: Helene Grogan
date: 2021-03-28 12:24:54 -0500
categories: grogan
---

I've been looking forward to trying out dictionary approaches on my corpus of threads from the QAnon Casualties subreddit, given that my primary research question has to do with the use of different types of language to make sense of the QAnon phenomenon. It'll be interesting to compare this with unsupervised learning methods later on, to see if I am missing any major themes or sets of words, but I think I've got some good starting points to look at, in terms of collections of words that indicate different framings of the issue.

I started with a list of words that seemed particularly prevalent in relation to the use of "cult"-related language to describe and make sense of QAnon, which was key to my initial research question for this project. As of this writing, this is my list of words for that dimension:

```r
cult_words
 [1] "cult"       "qult"       "qcult"      "qkult"      "culty"      "deprogram*" "brainwash*" "cultish"   
 [9] "savior"     "messiah"    "worship*"   "cultic"
```

As a comparison case, I put together a list of words that would indicate more of a political framing of QAnon, either in terms of party politics (particularly those centered on Trump) or in terms of political radicalization. I expect that the political and cultic approaches will overlap quite a bit, but that, too, provides some insight into whether people are framing QAnon as a specifically *political* cult. Here is my list of political words at this time:

```r
pol_words
 [1] "politic*"    "conservati*" "republican"  "trump*"      "right-wing*" "gop"         "radicaliz*" 
 [8] "extremis*"   "coup"        "liberal*"    "libs"        "democrat*"   "left-wing*"  "dems"  
```

Then I just recently added a third category, which I can't believe it took me so long to consider, which was the framing of QAnon beliefs as indicative of mental illness. From my sporadic reading of the subreddit, this type of language has been present from the beginning (particularly in the use of the word "crazy") but seems to be growing more prevalent in recent weeks; I'll be interested to see what this all looks like over time. But first, here is my list of words related to mental illness (several of which are colloquial and frankly ableist, for which I apologize, but since they *have* been part of the discourse, I didn't want to miss them):

```r
MI_words
 [1] "mental"     "crazy"      "schizo*"    "psycho*"    "derange*"   "psycholog*" "nuts"       "delusion*" 
 [9] "insan*"     "paranoi*"
```

So after I read all of these word lists into R, I combined them into a dictionary, applied it to my corpus to create a dfm with these three sets of words as the features, and converted the newly-created dfm into a dataframe:

```r
# Create a dictionary from my word lists
my_dict <- dictionary(list(cult = cult_words,
                           politics = pol_words,
                           MI = MI_words))

# Apply the dictionary to my corpus to create a dfm
qcdfm_words <- dfm(qccorpus, dictionary = my_dict, valuetype = "glob")

# Convert to a dataframe, keeping the docvar (which has the date)
df_words <- cbind(convert(qcdfm_words, to = "data.frame"), docvars(qcdfm_words))
```

This gives me something that looks like this (for a total of 3089 threads):

```r
      doc_id cult politics MI       date
3084 ltyzvj    0        0  0 2021-02-27
3085 ltzrrg    1        7  1 2021-02-27
3086 lu0bqq    0        4  6 2021-02-27
3087 lu48il   11       50 11 2021-02-28
3088 lu4fnt    8       60  4 2021-02-28
3089 lu4wgv    0        0  0 2021-02-28

```

You might notice that I've trimmed down the thread_id field to just the alphanumeric code embedded in each link, instead of the alphanumeric plus the part of the link derived from the title. I did some testing and discovered that the shorter version still gives me a unique identifier, and makes the data a little more compact. There is some loss of context from not seeing that piece of the title, but in the spirit of all the "semantic violence" we're already doing through chopping up the text, I thought it was appropriate.

## Prevalence and Correlation of Different Terms

To get an idea of the prevalence of each word type, I looked at the proportion of threads using each one:

```r
# Proportion using "cult" language
length(which(df_words$cult > 0)) / nrow(df_words)
[1] 0.494011

# Proportion using political language
length(which(df_words$politics > 0)) / nrow(df_words)
[1] 0.7287148

# Proportion using mental illness language
length(which(df_words$MI > 0)) / nrow(df_words)
[1] 0.5917773

# Proportion that use all three
length(which(df_words$MI > 0 & df_words$politics >0 & df_words$cult > 0)) / nrow(df_words)
[1] 0.3382972

# Proportion of threads that don't use ANY of those words
length(which(df_words$cult == 0 & df_words$politics == 0 & df_words$MI == 0)) / nrow(df_words)
[1] 0.1443833
```

All three framings seem very common, with political language being the most prevalent (72.9%), followed by words related to mental illness (59.2%), and finally the language of cults (49.4%). Over a third of threads in my dataset use words from all three word lists, and only 14.4% of threads don't use any of these three sets of terms. Then I threw in some glimpses of the overlap between sets of words:

```r
# Proportion of threads using political language that ALSO use cult language
length(which(df_words$politics > 0 & df_words$cult > 0)) / length(which(df_words$politics > 0))
[1] 0.5872945

# Proportion of threads using cult language that also use mental illness language
length(which(df_words$cult > 0 & df_words$MI > 0)) / length(which(df_words$cult > 0))
[1] 0.750983

# Proportion of threads using political language that also use mental illness language
length(which(df_words$politics > 0 & df_words$MI > 0)) / length(which(df_words$politics > 0))
[1] 0.6836961

```

I thought it was interesting that *of the ~73% of threads that use political language*, the majority of those (~59% of them) *also* use cult language, and 68.4% use mental illness language. And of the 49% of threads that use cult language, the vast majority (75%) also use mental illness language.

So, as expected, there is quite a bit of overlap. I also looked at the correlations between sets of terms:

```r
# Correlation of cult and political language
cor(df_words$cult, df_words$politics)
[1] 0.47228

# Correlation of cult and mental illness language
cor(df_words$cult, df_words$MI)
[1] 0.4929963

# Correlation of political and mental illness language
cor(df_words$politics, df_words$MI)
[1] 0.4409184

```

I would call these moderate-to-strong positive correlations, indicating that there is a relationship between how these different framings of QAnon are being used in the discussions.

## Change Over Time

My next step with this approach is to consider how the use of these different sets of terms may have changed over time. At the moment, I am working with a corpus based on threads from December 17, 2020 through February 28, 2021; I have continued to collect data since then, but I froze the dataset in early March so it wouldn't keep changing as I applied various techniques. Toward the end of the semester I plan to re-run my processing scripts to incorporate the newer threads into a larger corpus, but for now I'm going to keep things consistent. 

However, first I had to do some work to get the thread dates into a consistent format; some were in dd-mm-yy format, then they switched to d/m/yy format, then they switched back to dd-mm-yy at some point. (Argh.) This was something that broke my data-collection scripts more than once around the beginning of the year, because I have them check the date to allow time for comments to accumulate before I collect them. So I had to address that first.

Luckily, I encountered the R package "lubridate," which made it super easy to standardize the date format. The package includes a method called "parse_date_time," which just needs to know what possible date orders are present in the data. In my case, that was either day-month-year or month-day-year -- and *it doesn't care* what punctuation is used to separate the digits (like dashes versus slashes). So this did the trick:

```r
library(lubridate)
text_content$date <- parse_date_time(text_content$date, orders = c('dmy', 'mdy'))
```

After that, I created a new dataframe collecting the count of each type of word by date, then spent a LOT of time trying to get any kind of plot to work. I finally ended up using this code:

```r
ggplot(words_by_date, aes(Date)) + 
    geom_line(aes(y = Cult, colour = "Cult", group=1)) + 
    geom_line(aes(y = Politics, colour = "Politics", group = 1)) +
    geom_line(aes(y = MI, colour = "MI", group = 1)) + 
    labs(x = "Date", y = "Count") + 
    theme(axis.text.x = element_text(angle = 90))
```

Which gave me this plot:

![plot of word use over time](https://github.com/douglas-r-rice/douglas-r-rice.github.io/blob/main/_posts/Grogan-4-wordsovertime.png?raw=TRUE)

Since this kind of looked like the frequencies of all three word types were mostly following similar patterns (which was unsurprising given how correlated they are), I thought I would also plot the frequency of *posts* by date to see if that was accounting for the patterns in word counts. That gave me this:

![plot of posts over time](https://github.com/douglas-r-rice/douglas-r-rice.github.io/blob/main/_posts/Grogan-4-postsovertime.png?raw=TRUE)

That looks to me like the changes in word counts over time *are* mainly based on the volume of posts over time. So what might be more interesting is to plot the changes in *proportion* of each type of language being used over time, and/or to use a different measure of word frequency instead of the raw count. But that will have to wait for another time.

## Next Step: Unsupervised Learning Methods

As I mentioned above, I'm also eager to see how these dictionary-based results compare with, say, topic modeling of the same corpus. I have already updated my word lists multiple times as I think of (or come across) new terms that fit, so I am likely still missing some. But for now, I am pretty happy with how this is shaping up, and I'm already seeing some interesting relationships. Until next time!