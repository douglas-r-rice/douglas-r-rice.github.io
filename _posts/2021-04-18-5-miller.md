---
layout: post
title: "Understanding Influence Using Topic Models (Miller)"
author: Larri Miller
date: 2021-04-18 12:24:54 -0500
categories: miller
---


Time to dig in to Topic Modeling! My overarching goal is to see how influencers shift the conversation. I haven't identified influencers yet (that will be done in my social networks class, and yes, I am behind) but in this blog post I want to get a working script that will pick out topics in my dataset. That way I can just add in a binary variable once influencers have been identified and have the topic modeling already prepped.

Let's try LDA first. I'm loading in my tokenized doc that I saved from last blog:
```
tokens <- readRDS("SharpieTokens.rds")
```

```
library(text2vec)
head(tokens, 10)
```

can I just skip to vocabulary since what I have is already tokenized? Let's try
```
v <- create_vocabulary(tokens)
v
```

Oh, weird. It's not showing term counts, which seems like it would be a problem. I'm going to try the dfm that I created previously and actually run the token iterater to see if that changes it.
```
dfm <- readRDS("SharpieDFM.rds")
head(dfm, 10)
```

```
tokens <- word_tokenizer(dfm)
```

Okay,this gives me "error: vector memory exhausted (limit reached?)". My guess is that my current dfm -- 950,414,257 elements taking up 44.5 MB-- is too much for this to handle.