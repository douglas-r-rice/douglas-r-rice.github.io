---
layout: post
title: "Collecting SharpieGate Tweets (Miller)"
author: Larri Miller
date: 2021-02-28 12:24:54 -0500
categories: miller
---

I collected the dataset that I want to explore using the rtweet library and my personal Twitter developer account. This is an example of the code snippet I used, in case anyone is curious about collecting data through the Twitter API:

```{r}
library(rtweet)

# token information is specific to the developer account
mytoken <- create_token( 
  app = "",
  consumer_key = "",
  consumer_secret = "",
  access_token = "",
  access_secret = "")

df <- search_tweets("keyword", include_retweets = TRUE, n = 10000, retryonratelimit = TRUE,  token = mytoken)

write.csv(df, "filename.csv")
```

Now I want to refresh my memory on the dataset that I have:
```{r}
df <- read.csv("SharpieGate.csv")
nrow(df)
length(unique(df$user_id))
range(df$created_at)
head(unique(df$text))
```

My dataset contains 10,174 Tweets by 8,300 unique users created from 11/10/2020 to 11/20/2020. Previously I've done a network analysis on this dataset, but I have yet to examine any of the textual content (contained in the "text" variable). 


I'm going to try the week 4 NLP and Regex tutorial out with my dataset. 

```{r}
library(cleanNLP)
library(tidytext)
library(tidyverse)
library(quanteda)

cnlp_init_udpipe()
```

Not sure if I'll be able to use the texts() function with my current text variable, but lets try.

```{r}
text <- texts(df$text)
text[length(text)]
```

Looks like it worked! I can see that these tweets will need a lot of cleaning, though, based on the presence of characters like "â€™". Continuing with the tutorial.

```{r}
myData <- docvars(df$text)
head(myData)
```

This gives me an error saying that docvars() only works on corpus, dfm, readtext, tokens objects. My next steps will be to figure out how to work around this!
