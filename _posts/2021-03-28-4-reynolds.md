---
layout: post
title: "Named Entities in Political Podcasts (Reynolds)"
author: Nate Reynolds
date: 2021-03-28 12:24:54 -0500
categories: reynolds
---


During the past two weeks, I have dug deeper into what will be the heart of my project: extracting names of guests from podcast descriptions using natural language processing. A lot of my time and effort has been spent trying to implement this process into loops and functions, both of which I have done successfully.

For this blog post, it seems easier for me to just post the code chunks I've worked on and then describe what each does and what the thought process was behind them.

```
source("guestlook.R")
library(tidyverse)
library(quanteda)
```

First - I believe this was in my last blog as well - I create tokens out of my corpus. For this example I am using the corpus of data generated from the *Left, Right & Center* podcast, which includes the episodes of that podcast and other associated podcasts. See my last blog post for details on that. I mainly chose that corpus for this example just because it is relatively small (2670 observations) and therefore easy to experiment with. 

```
# take corpus, make clean tokens
lcr_tokens <- tokens(lcr_corpus, 
    remove_punct = T,
    remove_numbers = T,
    remove_symbols = T,
    remove_url = T)
lcr_tokens <- tokens_select(lcr_tokens,
                                pattern = c("p","br","nbsp", "b"), #keep stopwords for now 
                                selection = "remove")
```

As you will see, I take out numbers, symbols and URLS which may clutter episode descriptions. I also take out HTML code like `br` (coming from `<br/ >`) which once dictated formatting within episode descriptions. Importantly, I am keeping stop words for now, because stop words are important in identifying the language that may infer guest appearances. In this blog post, I will detail how I searched for the phrases "talk with" and "talk to" as markers that might precede the name of a podcast guest. If I removed stop words, I would have to search only for the word "talk" and would collect a lot more error in my searches.

The next code chunk includes my process of searching for guests with those phrases, as a loop. I tried to comment out what each line of code is doing, but as a general overview, this is creating a blank vector with one row for every podcast episode in the corpus and then filling that vector with information from each episode. The loop uses a regular expression to search for the phrases "talk with", "talks with", "talk to" and "talks to", then looks for named entities that take place after that phrase (but before the word "about", if that word appears), and finally extracts that name. I use the `spacyr` package for the named entity recognition. This took a lot of troubleshooting to figure out and some extra frustration to work into a loop, but it turned out functional.

```
# number of rows for the length of the loop
x_rows <- length(lcr_tokens)
# create blank vector for results
namevector <- vector(mode = "list", length = x_rows)
# the loop
for (i in 1:x_rows) {
    talkwith_phrase <- kwic(lcr_tokens[i], # look for the phrase
      pattern = phrase("talk[s]* (with|to)"), # regular expression
      window = 15, # take 15 word window before and after
      valuetype = "regex") # specify I am using regular expressions
    if (nrow(talkwith_phrase) == 0) {
      next # end the loop for episodes without the phrase
    }
    # look at words after the phrase, i.e. "talks with..."
    post_talkwith <- talkwith_phrase$post 
    # take words that come before "about" to avoid other named entities
    post_talkwith <- str_split(post_talkwith, "about", simplify = TRUE)[,1]
    # use spacyr to parse the remaining words
    post_talkwith_parse <- spacy_parse(post_talkwith)
    # identify named entities
    names <- entity_extract(post_talkwith_parse) %>%
      filter(entity_type == "PERSON") %>% # include persons only
      select(entity) %>% # just take the column of names
      as.list(.) # take as a list in case of multiple names, i.e. guests
    if (length(names) == 0) {
      next # end the loop if there are no named entities
    }
    if (length(names$entity) == 0) {
      next # end the loop if the entities are not names
    }
    # append the leftover names to the blank vector
    namevector[[i]] <- append(namevector[[i]], names)
}
```

This did work, and found about 50 names. As an example of what this is code is doing, an example episode description from my corpus from the podcast *Civic Revival* reads as follows: *To wrap up a somber week of remembrances, Josh and Kristen dive deep into the history and politics of the battle over Supreme Court confirmations to see what "precedent" they can find, they talk with author Andrew Sommers about promoting effective civic engagement, they clean up some leftovers on Ukraine and Kyle Rittenhouse, then they feel better noting how RBG continues making history, even in death.* The code above took all words which came after "talk with" and before "about", which left the string: "author Andrew Sommers". This method avoided the other named entities that obviously weren't guests like the hosts Josh and Kristen, or Kyle Rittenhouse and RBG. In that example, the final output appended onto the blank vector was "Andrew_Sommers".

Obviously, there are many other phrases that might precede the introduction of a guest in a podcast description, like "joined by", "interview", "sits down with", "call in", etc. I will have to make scripts for those eventually, but it should be much easier now that I have a template to work with.

The next code I wrote, displayed below, adds the names extracted from the last process into the corpus summary which are then updated as the corpus' docvars. Which, as you can see, is more complicated than it sounds.

```
# start with a new blank variable
lcr_summary$fixednames <- NA
# a loop, one iteration per episode
for (i in 1:x_rows) {
  if (is.null(namevector[[i]])) {
    next # skip if there were no guest names... most episodes
  }
  # this takes all unique names but saves them as a single character string
  # in case of multiple guests on the same episode
  lcr_summary$fixednames[i] <- namevector[[i]] %>%
  as.data.frame() %>% # dataframe in order to use dplyr function
  distinct() %>% # unique names in case names were repeated
  .[[1]] %>% # take the values out of the column
  toString() # combine multiple names into length 1
}
# update the doc vars
docvars(lcr_corpus) <- lcr_summary
```

There will be some name cleaning required - maybe to be integrated at some point earlier in the code - to remove occasional titles that get lumped in with names and to select the right name if multiple named entities were picked up in the same episode. Also, names should probably be standardized in some way, such as only first and last names, so that the same names can be matched across podcasts. I have experience with name cleaning and matching in R so I don't think this will be a problem at all. 

## Writing a Function

Given the extension on the due date for this blog post, I had the time to create a function for this code that takes in a tokens object and a regular expression as an input and outputs the guest names it finds with that regular expression. The full code for this function is tedious and pretty repetitive from what was included before so I put it in an appendix at the end of this blog post. But for illustration, here is the function `guestlook()` in use to identify the same phrase as before.

```
namevector <- guestlook(tokens = lcr_tokens,
          what = "talk[s]* (with|to)", win = 15, look = "post",
          about = TRUE, to = FALSE, restart = TRUE)
```

I will explain what each argument is doing:

1. `tokens` specifies the tokens object to be used. 
2. `what` specifies the regular expression for the phrase that will signal the name of a guest
3. `win` stands for window, the number of words before or after to look at from the phrase
4. `look` specifies whether the name comes before or after the signal phrase
5. `about` specifies whether to cut off the search window before the word "about", i.e. "we talk to Person X about Person Y", in which case Person X is the guest
6. `to` specifies whether to cut off the search window before the word "to", i.e. "Person Y joins the podcast to discuss Person X", in which case Person Y is the guest
7. `restart` specifies whether we are starting a new `namevector` object and in order to begin with a blank vector the same length as the corpus. For subsequent uses of the function, as long as you keep naming the output "namevector", it will amend the newly found names onto that same vector.

For more examples, I used the function as shown below to find guest names that come after the word "joined", i.e. "we are joined by Person X", or before the word "joins", i.e. "Person Y joins us this week". From visual inspection I could tell these were common phrases that include guest names. 

```
namevector <- guestlook(tokens = lcr_tokens,
          what = "joined", win = 15, look = "post",
          about = FALSE, to = TRUE, restart = FALSE)
namevector <- guestlook(tokens = lcr_tokens, 
          what = "joins", win = 15, look = "pre", 
          about = FALSE, to = FALSE, restart = FALSE)
```

From these three searches, I found guest names in 134 of 2,670 podcast episodes in my sample dataset. Obviously, there are many more phrases to look for, like "interview", "sits down with", or simply "guest". And fundamentally, I am unable to perfectly find all guest features using hand-coded searches like these because certain descriptions follow no ordinary patterns - or I will cast my net so wide that I will pick up names that aren't guest features. Regardless, it's a start and it's something to worth with. I'm sure there is some more sophisticated machine learning that I would better identify the terms that signal names of guests in a podcast episodes, but that is beyond my scope right now. This is not merely categorizing different texts, as the machine learning examples in the last tutorial were. This is finding specific names within documents that are embedded in human-written language.

My next steps are to write more iterations of the `guestlook()` function to conduct a deeper search of guest names. Then I will take the full list of all guest names found in this round, collapse it to unique names, and run a non-snowballed scrape of more podcast episodes from podcasts by those names. One of the problems with my original web-scraping endeavor was that the code sometimes searched for the same name over and over again, collecting hundreds of duplicate episodes from the same podcasts. In this way - finding all of the guests to look for first, then searching - I will save an extroardinary amount of processing time and will be able to repeat that process very easily.

### Appendix: The Guestlook Function

Here is the full code for the function I wrote to find names of guests from podcast episode descriptions using a given regular expression:

```
guestlook <- function(tokens, what, win=15, look="post", about=FALSE, to=FALSE, restart=FALSE) {
  # number of rows for the length of the loop
  xrows <- length(tokens)
  # create blank vector for results, if I need
  if (!exists("namevector")|restart == TRUE) {
    namevector <- vector(mode = "list", length = xrows)
  }
  # the loop
  for (i in 1:xrows) {
    phrase <- kwic(tokens[i], # look for the phrase
                            pattern = phrase(what), # regular expression
                            window = win, # take 15 word window before and after
                            valuetype = "regex") # specify I am using regular expressions
    if (nrow(phrase) == 0) {
      next # end the loop for episodes without the phrase
    }
    # look at words before or after the phrase, i.e. "talks with..." vs. "...joins us"
    if (look == "pre") {
      phrase <- phrase$pre 
    } else if (look == "post") {
      phrase <- phrase$post 
    } else {
      phrase <- phrase$post 
    }
    # take words that come before "about" to avoid other named entities
    if (about == TRUE) {
      phrase <- str_split(phrase, " about ", simplify = TRUE)[,1]
    }
    # take words that come before "to" to avoid other named entities
    if (to == TRUE) {
      phrase <- str_split(phrase, " to ", simplify = TRUE)[,1]
    }
    # use spacyr to parse the remaining words
    phrase_parse <- spacy_parse(phrase)
    # identify named entities
    names <- entity_extract(phrase_parse) %>%
      filter(entity_type == "PERSON") %>% # include persons only
      select(entity) %>% # just take the column of names
      as.list(.) # take as a list in case of multiple names, i.e. guests
    if (length(names) == 0) {
      next # end the loop if there are no named entities
    }
    if (length(names$entity) == 0) {
      next # end the loop if the entities are not names
    }
    # append the leftover names to the blank vector
    namevector[[i]] <- append(namevector[[i]], names)
  }
  namevector
}
```

