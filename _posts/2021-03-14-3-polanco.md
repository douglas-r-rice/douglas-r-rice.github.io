---
layout: post
title: "A Corpus of Dissertations (Polanco)"
author: Diego Polanco
date: 2021-03-14 12:24:54 -0500
categories: polanco
---



In this post I will move forward to finish the webscrapping process of building the data set of dissertation. So far, I already have achieved to identify the name and author of every dissertation 

```{r, include=TRUE}
tibble(df) %>% print()
```

It is hard to notice in a first glance, however the column name in string format is "polluted" by having also the title of the dissertation included. This shouldn't be an issue. Now I need a code fixing that and get only the dissertation's author in the name column of our data frame. I had a code ready for this, however I've been working for my students in econometrics and therefore in my coding in general to follow a tidyverse structure. I'm not convinced that this always will be better for my coding but I'm sure that I need to at least learn it. The thing is that in building the code to implement a simple "splt" of a column I runo into that the split function brings you to a list and I'm struggling a little bit  


```{r, include=TRUE}

####Cleaning name variable 

#We use str split to clean the variable name from the title attached 


x <- df$name %>% 
  str_split(fixed(df$title),simplify=T)
x<- as.vector(x[,2]) %>% 
    str_split(",",simplify=T)
df$name<-as.vector(x[,2])

rm(x)
tibble(df)

```


In the following code I present an iteration process to go over each link for each author and get information that is available in the metadata of each dissertation website. Mainly I'm interested in two fields of information over which I'll work my analysis: the abstract of the dissertation and the body of advisor of each student. As I previously mention my research project aims to cross text analysis of the abstract - and maybe in the future the text of the dissertation themselves, with the embedded network of knowledge production created by the overlapping advising from faculty to graduate students. 


```{r, include=TRUE}
#Eliminating duplicates 

df <- df[!duplicated(df$name),] 



#Creating iteration of webscraping through each website 

df$n<-seq(1,nrow(df))


for (i in 1:nrow(df)){

#print(i)

URL<- df$link[which(df$n==i)] %>% toString()
userpass <- "dpolanconeco:Cardoncillo2081"
h<-handle_setopt(handle=new_handle(), userpwd = userpass)
x<-curl_download(URL, destfile = "author.txt", handle = h) %>% read_html()

#BP Categories 
y1<-html_nodes(x,'#bp_categories p') %>% html_text()
  if (identical(y1, character(0))){
  y1<-"NA"
  }
  y1<-as.character(y1)

#Abstract 
y2<-html_text(html_nodes(x,'#abstract p'))

if (length(y2)==1){
aux=y2
}

if (length(y2)>1){

for (j in 1:length(y2)){
          
  if (j==1){  
    #print(j)
          aux<-y2[j]
          }
          else{
    #print(j)        
          aux<-y2[1]
          aux<-paste(aux,y2[j])            
          }
  }
} 

if (length(y2)==0){
aux="NA"  
}
y2<-aux 



#Advisors 
y3 <-html_text(html_nodes(x,'#advisor5 p , #advisor4 p , #advisor3 p , #advisor2 p ,#advisor1 p'))
if (length(y3)==1){
y3[2] <- ""  
y3[3] <- ""    
y3[4] <- ""  
y3[5] <- ""    
}
if (length(y3)==3){
y3[4] <- ""  
y3[5] <- ""    
}
if (length(y3)==4){
y3[5] <- ""    
}

a <- y3
if (identical(a, character(0))){
y3<-c("NA","NA","NA","NA","NA")
}

#PDF Address 
y4<-html_attr(html_nodes(x,'#pdf'),'href')


#Recomendeed citation 
y5<-html_text(html_nodes(x,'#recommended_citation p'))
y5<-gsub(pattern="\n", replacement="", y5)


a <- y5
if (identical(a, character(0))){
y5<-html_text(html_nodes(x,'.citation+ p'))
y5<-gsub(pattern="\n", replacement="", y5)
}

aux<-data.frame(t(c(i,y1,y2,y3,y4,y5)),stringsAsFactors = FALSE)
names(aux) = c("n","bp_categories","abstract","adv1","adv2","adv3","adv4","adv5","pdfhtml","rcit")

if(i==1){
df=merge(df,aux, by="n", all =TRUE)
}

else{
df[i,6:14]<-aux[-1]
}
}


rm(aux,x)
rm(list=ls(pattern ="y"))
rm(a,h,i,j,URL,userpass)


str(df)

```

As can be apprciated when we call the structure of the data set the variables of advisors, abstract - among others - are incorporated. From now onward I'll work on analyizing the set of abstract as a corpus of text. 
