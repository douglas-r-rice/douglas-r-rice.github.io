---
layout: post
title: "Topic Modeling of QAnon Discussions (Grogan)"
author: Helene Grogan
date: 2021-04-18 12:24:54 -0500
categories: grogan
---


To get started with topic modeling, I tried a Latent Dirichlet Allocation (LDA) model. This model assumes there is no correlation between topics, which is an assumption I suspect is violated in my data set, given my previous experience with dictionary approaches. But I wanted to give it a try anyway and see what I got.

Trial and error with different values of K suggested that about 15 topics worked well, so I used that value for all of my attempts. (And by "worked well," I mean that the topics seemed cohesive and distinct from each other; 10 topics led to some combinations of themes I didn't think were as coherent, and 20 led to some topics that just looked like collections of words that didn't hang together as well.) Using the text2vec package, I took my data set of discussion threads with the text all collapsed into a single field, tokenized it (including removing punctuation), and created a vocabulary. Fitting the LDA model resulted in the following topics, shown as columns containing the top 10 words for each:

```
topics1
      [,1]           [,2]         [,3]          [,4]         [,5]         [,6]        [,7]      
 [1,] "president"    "school"     "party"       "pedophiles" "boundaries" "watching"  "child"   
 [2,] "march"        "black"      "vote"        "spend"      "abusive"    "e9"        "police"  
 [3,] "inauguration" "white"      "republicans" "anxiety"    "adult"      "approach"  "abuse"   
 [4,] "date"         "town"       "jews"        "fear"       "contact"    "watched"   "violence"
 [5,] "military"     "south"      "republican"  "must"       "safe"       "open"      "gun"     
 [6,] "4th"          "area"       "nazi"        "shame"      "toxic"      "sharing"   "custody" 
 [7,] "martial"      "generation" "jewish"      "admit"      "deserve"    "listen"    "cops"    
 [8,] "20th"         "racist"     "war"         "craziness"  "move"       "questions" "sex"     
 [9,] "law"          "rural"      "nazis"       "healthy"    "guilt"      "falling"   "violent" 
[10,] "inaugurated"  "college"    "democrats"   "vulnerable" "cut"        "npr"       "threat"  

      [,8]              [,9]           [,10]            [,11]          [,12]         [,13]       [,14]     
 [1,] "therapy"         "christian"    "youtube"        "sister"       "bet"         "parler"    "vaccine" 
 [2,] "addiction"       "church"       "russia"         "brother"      "money"       "report"    "gold"    
 [3,] "qanoncasualties" "religion"     "disinformation" "husband"      "twitter.com" "fbi"       "vaccines"
 [4,] "r"               "religious"    "channels"       "father"       "soros"       "account"   "doctor"  
 [5,] "therapist"       "bible"        "sites"          "aunt"         "pence"       "watkins"   "doctors" 
 [6,] "message"         "jesus"        "8kun"           "grandma"      "texas"       "porn"      "virus"   
 [7,] "www.reddit.com"  "christians"   "reply"          "son"          "21"          "capitol"   "gates"   
 [8,] "removed"         "faith"        "channel"        "uncle"        "win"         "a0"        "mark"    
 [9,] "marriage"        "christianity" "algorithms"     "grandmother"  "status"      "reported"  "beast"   
[10,] "sub"             "antichrist"   "platform"       "grandparents" "tomorrow"    "reporting" "uk"    

      [,15]       
 [1,] "evidence"  
 [2,] "research"  
 [3,] "analysis"  
 [4,] "psychology"
 [5,] "article"   
 [6,] "cults"     
 [7,] "epstein"   
 [8,] "critical"  
 [9,] "facts"     
[10,] "debunk"
```
Note that the first one seems not only related to the presidential inauguration on January 20, but also includes references to the idea (popular in QAnon circles) that March 4 would be the true inauguration date, and the one on which Donald Trump would again be sworn in as the real U.S. president (which would also involve the invocation of martial law). Other topics capture aspects of the QAnon conspiracy theory, such as the notion of widespread child sex trafficking by a cabal of pedophiles (Topics 4 and 7), its religious elements (Topic 9), and its overlap with Covid-19 conspiracies (Topic 14). Topic 3 hones in on the political dimension of the discussion (as well as some of its anti-Semitic overtones), and Topic 11 captures the fact that many people are discussing family members who have been caught up in QAnon.

You might notice that there is redundancy within some topics, like the presence of "vaccine" and "vaccines" in Topic 14. This is because (following my earlier pre-processing decisions) I did not stem the words in my corpus before fitting the model. To see if that made a difference, I fitted another LDA model, this time with stemming. There were some differences in that model, but overall it seemed pretty similar. Ultimately, though, I was somewhat more partial to the unstemmed results, because they seemed a little more cohesive, and I don't think the redundancy of a few words detracts from that cohesiveness; if anything, it indicates the strength of certain subjects within a given topic.

My biggest concern, though, was related to the fact that I started by re-tokenizing my data set using text2vec, rather than using the original set of tokens I created when I made all of my pre-processing choices early on. So there are URLs still included, as well as symbols and stop words. Many of the stop words were removed by pruning my vocabulary for the model, but not necessarily all of them. So I decided to see what it looked like if I used my original set of tokens with all of my pre-processing in place (including the choice to avoid stemming). To do this, I needed to convert it from a quanteda "token" object to a list, but that seemed to work smoothly. The resulting topics looked like this (going out to 16 words for each topic this time):

```
topics3
      [,1]          [,2]        [,3]           [,4]        [,5]          [,6]       [,7]         [,8]          
 [1,] "school"      "american"  "capitol"      "twitter"   "racist"      "gold"     "town"       "vaccine"     
 [2,] "college"     "china"     "antifa"       "removed"   "white"       "money"    "area"       "vaccines"    
 [3,] "teacher"     "chinese"   "blm"          "parler"    "forgive"     "jones"    "rural"      "doctor"      
 [4,] "taught"      "russia"    "party"        "report"    "feelings"    "alex"     "local"      "brother"     
 [5,] "cps"         "jewish"    "vote"         "account"   "hurt"        "court"    "interested" "mask"        
 [6,] "high"        "jews"      "fbi"          "fb"        "actions"     "security" "city"       "masks"       
 [7,] "escape"      "countries" "republican"   "speech"    "hatred"      "legal"    "south"      "aunt"        
 [8,] "trust"       "america"   "republicans"  "reporting" "respect"     "mark"     "areas"      "sister"      
 [9,] "teach"       "russian"   "supporters"   "r"         "comment"     "beast"    "county"     "medical"     
[10,] "adults"      "canada"    "democrats"    "accounts"  "forgiveness" "silver"   "university" "wearing"     
[11,] "kid"         "soros"     "civil"        "pope"      "trans"       "access"   "student"    "virus"       
[12,] "minor"       "canadian"  "votes"        "clone"     "racism"      "value"    "interview"  "wear"        
[13,] "responsible" "texas"     "bernie"       "app"       "black"       "document" "resources"  "doctors"     
[14,] "job"         "history"   "voted"        "users"     "removal"     "attorney" "meth"       "baby"        
[15,] "sound"       "foreign"   "conservative" "banned"    "protests"    "grid"     "journalist" "vaccinated"  
[16,] "class"       "europe"    "voting"       "sub"       "im"          "stock"    "request"    "grandparents"

      [,9]            [,10]           [,11]         [,12]          [,13]        [,14]            [,15]         
 [1,] "video"         "cults"         "child"       "march"        "therapy"    "movement"       "christian"   
 [2,] "sources"       "society"       "trafficking" "bet"          "therapist"  "campaign"       "church"      
 [3,] "youtube"       "book"          "sex"         "president"    "daughter"   "leaders"        "religion"    
 [4,] "conversation"  "susceptible"   "pedophiles"  "inauguration" "addiction"  "propaganda"     "bible"       
 [5,] "facts"         "meaning"       "4chan"       "date"         "happy"      "governments"    "jesus"       
 [6,] "listen"        "fear"          "pedophile"   "4th"          "husband"    "et"             "religious"   
 [7,] "questions"     "lack"          "epstein"     "20th"         "parent"     "cultural"       "christians"  
 [8,] "watching"      "addictive"     "watkins"     "inaugurated"  "boundaries" "certain"        "christianity"
 [9,] "approach"      "religions"     "porn"        "tomorrow"     "abusive"    "wealth"         "faith"       
[10,] "engage"        "understanding" "pedophilia"  "lol"          "marriage"   "authoritarian"  "evangelical" 
[11,] "conversations" "easily"        "hollywood"   "plan"         "heart"      "fascist"        "catholic"    
[12,] "flat"          "interests"     "jim"         "storm"        "dealing"    "profit"         "antichrist"  
[13,] "research"      "complex"       "cabal"       "wait"         "hugs"       "movements"      "rush"        
[14,] "listening"     "self"          "secret"      "martial"      "divorce"    "promoting"      "raised"      
[15,] "debunking"     "belief"        "tom"         "goalposts"    "partner"    "disinformation" "pastor"      
[16,] "debunk"        "education"     "satanic"     "darkness"     "glad"       "example"        "atheist" 

```

That looks like a good set of LDA topics to me, with really clear themes coming through in each topic. The distribution of topics in the data set looked like this:

![plot of topic proportions in the data set](https://github.com/douglas-r-rice/douglas-r-rice.github.io/blob/main/_posts/Grogan-5-topicprops.png?raw=TRUE)
So the most common topic was #9, which has to do with issues of critical thinking, debunking, and engaging in conversations with loved ones who believe in QAnon. The second was #1, which I read as indicative of the unfortunate position many of the QAnon Casualties posters are in, which is that of being high school or college students living with parents who are caught up in QAnon, and feeling trapped in those circumstances. After those, the next three most common topics were #10, which has to do with the cult-like, quasi-religious aspect of QAnon beliefs, and its addictive nature; Topic 11, which captures a lot of the key beliefs of QAnon itself, including child sex trafficking by Satanic Hollywood pedophiles; and Topic 13, which again references the relationships at the heart of a lot of the discussion, as well as the emotional struggles underlying many of the posts.

## Structural Topic Model Approach

My next step was to try a Structural Topic Model, which allows a) correlation among topics, and b) the inclusion of additional variables as predictors. I decided to use the date of the original post for each thread as the predictor, as a way of incorporating a time measure as a factor in what the forum discussions were about. I ran this as a linear model at first, and just used the date field as-is (which was a character vector, which caused trouble for me later). This worked ok, but when I tried to really dig into it and plot the changes over time in a way that allowed for non-linearity, I realized I needed to convert the date field to a numeric value. I did this in two stages, first converting the character dates to Date objects, then creating a new docvar field in which they were converted to numeric values (interpreted as days since the Unix epoch of January 1, 1970):

```
# First, convert the date docvar for the qctokens object to a Date object
# Then add a second docvar giving that date as a days since the Epoch numeric object

docvars(qctokens, "date") <- as.Date(docvars(qctokens)$date)
docvars(qctokens, "posted") <- as.numeric(docvars(qctokens)$date)
```

Then I ran the STM function to fit the model, wrapping the "posted" covariate in a spline function to allow for non-linear variation. (I say that like I have any idea what that means under the hood, but when I plotted things later, they were definitely non-linear so I assume it worked.)

```
stm_qc_s <- stm(dfm_qc,
              K = k, 
              prevalence =~ s(posted),
              data = docvars(qctokens), 
              max.em.its = 1000, 
              seed = 1234, 
              init.type = "Spectral")
              
topics_stm_s <- labelTopics(stm_qc_s)
topics_stm_s$frex
        
 [1,] "fbi"         "parler"       "antifa"     "removed"      "report"      "capitol"      "speech"     
 [2,] "fox"         "news"         "videos"     "watch"        "youtube"     "believes"     "dad"        
 [3,] "podcast"     "clearance"    "watkins"    "hassan"       "ich"         "journalist"   "jim"        
 [4,] "hanks"       "tom"          "jewish"     "soros"        "jews"        "john"         "limbaugh"   
 [5,] "boundaries"  "relationship" "therapy"    "therapist"    "anxiety"     "marriage"     "feelings"   
 [6,] "custody"     "cps"          "safe"       "18"           "school"      "counselor"    "lawyer"     
 [7,] "bible"       "christians"   "church"     "christianity" "christian"   "pastor"       "jesus"      
 [8,] "sister"      "siblings"     "father"     "loss"         "grandma"     "mother"       "miss"       
 [9,] "forgiveness" "cults"        "forgive"    "susceptible"  "addiction"   "vulnerable"   "personality"
[10,] "march"       "4th"          "date"       "inauguration" "inaugurated" "20th"         "predictions"
[11,] "texas"       "rural"        "county"     "town"         "oklahoma"    "south"        "blue"       
[12,] "vaccine"     "vaccines"     "vaccinated" "wedding"      "beast"       "chiropractor" "flu"        
[13,] "gold"        "bernie"       "silver"     "gop"          "currency"    "vote"         "voters"     
[14,] "trafficking" "sexual"       "epstein"    "pedophilia"   "pedophiles"  "pedophile"    "meth"       
[15,] "epoch"       "ccp"          "chinese"    "china"        "gong"        "falun"        "trans"  
```

These are read with one topic per row this time, instead of by columns. As before, these topics seem highly relevant to the content of discussions on this forum, and many of the topics are direct parallels of topics in the LDA model. Their distribution in the data set looked like this:

![STM topic distribution in the discussions](https://github.com/douglas-r-rice/douglas-r-rice.github.io/blob/main/_posts/Grogan-5-topSTM.png?raw=TRUE)
It then took some experimentation to plot the actual change over time of these topics, but eventually this is the code I used to create a grid of 15 plots, with time on the x-axis (broken out by week), and expected topic proportion on the y-axis.

```
# First, create a sequence of dates indicating the weeks within the time frame of my data
library(lubridate)
weekseq <- seq(from = dates[1], to = dates[length(dates)], by = "week")
weekseq2 <- paste(month(weekseq), day(weekseq), sep="-")

# Set up the plot parameters to create a 5x3 grid, and set some reasonable margins
par(mfrow=c(5,3), mai=c(0.4,0.3,0.3,0.3))

# Then loop over my k=15 topics and plot each one over time
for (i in 1:k){
    plot.estimateEffect(modelEffects, 
                        covariate = "posted",
                        model = stm_qc_s, 
                        topics = modelEffects$topics[i], 
                        method = "continuous", 
                        main = myTopicLabels[i], 
                        printlegend=F, 
                        xaxt = "n",
                        labeltype = "custom",
                        linecol="grey26", 
                        xlab = "Time",
                        ylab = "Prop",
                        custom.labels = c())
    axis(1, at=weekseq, labels = weekseq2, las = 2)
    par(new=F)
}
```

The results looked like this:

![grid of plots of topics over time](https://github.com/douglas-r-rice/douglas-r-rice.github.io/blob/main/_posts/Grogan-5-topicgrid.png?raw=TRUE)

There seem to be clear effects of time-linked events on some topics, especially the January 6th insurrection and the January 20th presidential inauguration. Other topics stayed more or less even over time (such as boundaries-relationship-therapy-therapist-anxiety), while others seemed to get suppressed by the political turmoil in January, then climbed back up in February (such as vaccine-vaccines-vaccinated-wedding-beast). All in all, this was a really interesting exercise, and it seems like topic modeling yields a lot of relevant resuls for this set of Reddit data.