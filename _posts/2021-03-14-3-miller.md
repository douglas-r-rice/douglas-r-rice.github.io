---
layout: post
title: "SharpieGate (Miller)"
author: Larri Miller
date: 2021-03-14 12:24:54 -0500
categories: miller
---


In the past two weeks I've been trying to think more concretely about what my research question is. One possible avenue is trying to parse out the difference between the way Democrats and Republicans are talking about \#SharpieGate. I could also look at the difference in language between those who are verified on Twitter versus those who are not. I'm not sure if there's a variable for this in my dataframe, so let's check:

```{r eval = FALSE}
# setting eval to false because this has 90 variables and that is way too much for everyone to scroll through in a blog post :)
df <- read.csv("SharpieGate.csv")
head(df)
```

Yes! I see that there are two variables that mention verfication: "quoted_verified," "retweet_verified," and "verified." All contain "TRUE," "FALSE," and "NA" when applicable. Looks like the first one has many NAs. I also see that my dataset contains "description" which seems to contain a description of the user's bio. This meta-data has more than I realized, which is exciting! I'm going to look at the search_tweet() function more closely to see what it tells me about the data I've collected.

```{r eval=FALSE}
library(rtweet)
?search_tweets
```

The above line directed me to [this documentation](https://developer.twitter.com/en/docs/twitter-api/v1/tweets/search/api-reference/get-search-tweets) for more information, but it doesn't tell me much of anything about the metadata. Now that I've looked through it I've confirmed that my dataset does contain retweet data, meaning that it has information for users of tweets that are never retweeted, as well as data for both the user who retweeted and the user whose post was retweeted. (how many times would a rewteet tweet if a retweet could retweet, lol)

If I want to go the verified route, I could see about creating a new column that is evaluated to "TRUE" if any of the above "verified" columns have a TRUE value. I haven't quite decided on what to do textually, so this can be a good exercise in the meantime.

```{r eval=FALSE}

df$verified_any <- ifelse((df$verified == TRUE)|
                            (df$quoted_verified == TRUE)|
                            (df$retweet_verified == TRUE),1,0)

sum(df$verified_any, na.rm=TRUE)
```

Okay, so it looks like 6,225 of my Tweets are either created by someone verified, or retweeted/quoted by someone verified. I'm not going to do any more digging into this particular area until I'm certain of what route I want to take, but it's nice to know that it's a possible path.

In terms of more textual variables, there's actually more than I originally realized: "quoted_description," "retweet_description," and "description" each contain bio information, which I had initially just looked up manually. I'm leaning towards the possibility of combining an analysis of the bio, verification status, and tweet-- potentially alongside stats about likes and retweets (which would help me connect this to network analysis). I'm thinking about manually coding ~ 200 tweets/associated metadata and then using predicted learning to categorize themes within my text.

Thinking about this further, it might be possible for me to identify key words in the bios of politicians and journalists (political and media elite, respectively) to get a better sense of who is in this dataset. I spoke to a Sociology PhD student doing similar work, and they advised that I check out Dorottya Demszky et al.'s 2019 article "Analyzing Polarization in Social Media: Method and Application to Tweets on 21 Mass Shootings," linked via arxiv [here](https://arxiv.org/abs/1904.01596).

To wrap up this blog, I want to continue trying to apply the tutorials to my data in order to practice these skills. Last time, I got an error saying that docvars() only works on corpus, dfm, readtext, tokens objects when running through Week 4's NLP and Regex tutorial. I've since learned that this error occurred because that step had already been done. 

Starting where I left off previously:
```{r eval=FALSE}
library(cleanNLP)
library(tidytext)
library(tidyverse)
library(quanteda)

annotated <- cnlp_annotate(df) #because I have 10k tweets, this took a bit of time!

annoData <- left_join(annotated$document, annotated$token, by = "doc_id")
head(annoData)
```
Following the tutorial, I'm checking to see if there's a change in the length of sentences over time. Looking at the annoData, it seems like the text variable I should look at is retweet_text and the timestamp is created_at.
```{r eval = FALSE}
# plot length of documents (in sentences) over time
annoData %>% 
  group_by(created_at) %>% 
  summarize(Sentences = max(sid)) %>%
  ggplot(aes(created_at, Sentences)) +
    geom_line() +
    geom_smooth() +
    theme_bw()
```

Makes sense that this time variable doesn't work-- the time stamp is super granular. For the sake of blog length, I'm going to skip to the next tutorial-- preprocessing.

```{r}
library(tidytext)
library(plyr)
library(tidyverse)
library(quanteda)
```

For now, I'm going to try dropping things like punctuation and capitalization.
```{r eval = FALSE}
tweet_tokens <- tokens(annoData, remove_punct = T)
```
I'm getting an error that says "tokens() only works on character, corpus, list, tokens objects." I'll have to work on that for the next post, along with creating more refined research questions. :)


