---
layout: post
title: "Estimating Conspiracies in Text (Li)"
author: Zichao Li
date: 2021-03-28 12:24:54 -0500
categories: li
---

I begun the process of creating a classifier by making training and testing sets, then evaluate the efficacy of naive bayes, SVM, and random forests classifiers.

```{}
# set seed
set.seed(12345)

# create id variable in corpus metadata
docvars(alltext_corpus, "id") <- 1:ndoc(alltext_corpus)
df <- as.data.frame(alltext_corpus)

# create training set (1% of data)
set.seed(12345)
N <- ndoc(alltext_corpus)
trainIndex <- sample(1:N,.01 * N) 
train_corpus <- corpus_subset(alltext_corpus, id%in%trainIndex)
train_df <- as.data.frame(train_corpus)

write.csv(train_df,file="train.csv")

#manually coded the train set and change the variable from factor to integer
codedtrain$Conspiracy.talking[codedtrain$Conspiracy.talking=="yes"]<-1
codedtrain$Conspiracy.talking[codedtrain$Conspiracy.talking=="no"]<-0
codedtest1$consp[codedtest1$consp=="yes"]<-1
codedtest1$consp[codedtest1$consp=="no"]<-0

#create initial test set
testIndex <- c(1:N)[-trainIndex]

#split test set and sample 1% as the first test set
set.seed(123)
N <- length(testIndex)
test1Index <- sample(1:N, .005 * N)
test1 <- corpus_subset(alltext_corpus, id%in%test1Index) %>% write.csv("test1.csv")
heldOutIndex <- testIndex[-test1Index]

#create dfm
corptrain <- corpus(codedtrain,
                   docid_field = "doc_id",
                   text_field = "test")
corptrain[2]<-codedtrain[3] #delete
train_dfm <- dfm(corptrain)

test1_corpus <- corpus(codedtest1,
                    docid_field = "doc_id",
                    text_field = "text")
test1_dfm<-dfm(test1_corpus)

heldOut_dfm <- corpus_subset(alltext_corpus, id%in%heldOutIndex)%>%dfm()
```

## Train and test

The accuracy tends out to be not high enough, so I coded more training data and test data. The updated train set has 3% of the results the whole dataset, and test set has 2% of the results of the whole dataset. 

```{run Naive Bayes model on updated data subset}
#NaiveBayes
consp3_NaiveBayes <- textmodel_nb(train3_dfm, docvars(train3_dfm, "consp"), distribution = "Bernoulli") 
summary(consp3_NaiveBayes)

#apply model to test data
library(e1071)

test3Matched_dfm <- dfm_match(test3_dfm, features = featnames(train3_dfm))

# create a confusion matrix  
actual <- docvars(test3Matched_dfm, "consp")
predicted <- predict(consp3_NaiveBayes, newdata = test3Matched_dfm)
confusion <- table(actual, predicted)

# now calculate a number of statistics related to the confusion matrix
confusionMatrix(confusion, mode = "everything")
```

![](https://github.com/douglas-r-rice/douglas-r-rice.github.io/blob/main/_posts/Li-Naive bayes.png?raw=TRUE)


```{Run Support Vector Machine}
#small trainng sample
trainSmall_dfm <- corpus(codedtrain3,
                         docid_field = "doc_id",
                         text_field = "text",
                         unique_docnames = FALSE) %>%
  dfm(remove = stopwords("English"), remove_punct=T)

dim(trainSmall_dfm)

# run model
consp3_SVM <- textmodel_svm(trainSmall_dfm, docvars(trainSmall_dfm, "consp"))

# update test set
testMatchedSmall_dfm <- dfm_match(test3_dfm, features = featnames(trainSmall_dfm))

# create a confusion matrix 
actual_svm <- docvars(testMatchedSmall_dfm, "consp")
predicted_svm <- predict(consp3_SVM, newdata = testMatchedSmall_dfm)
confusion_svm <- table(actual_svm, predicted_svm)

# now calculate a number of statistics related to the confusion matrix
confusionMatrix(confusion_svm, mode = "everything")
```

![](https://github.com/douglas-r-rice/douglas-r-rice.github.io/blob/main/_posts/Li-SVM.png?raw=TRUE)


```{Run random forest}
library(randomForest)

dfmTrainSmallRf <- convert(trainSmall_dfm, to = "matrix")
dfmTestMatchedSmallRf <- convert(testMatchedSmall_dfm, to = "matrix")

set.seed(444)
consp_RF <- randomForest(dfmTrainSmallRf, 
                            y = as.factor(docvars(trainSmall_dfm)$consp),
                            xtest = dfmTestMatchedSmallRf, 
                            ytest = as.factor(docvars(testMatchedSmall_dfm)$consp),
                            importance = TRUE,
                            mtry = 20,
                            ntree = 100)
actual <- as.factor(docvars(testMatchedSmall_dfm)$consp)
predicted <- consp_RF$test[['predicted']]
confusion <- table(actual,predicted)
confusionMatrix(confusion, mode="everything")
```

![](https://github.com/douglas-r-rice/douglas-r-rice.github.io/blob/main/_posts/Li-Random Forest.png?raw=TRUE)
